---
---

@string{CVPR = {{IEEE/CVF} Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>)}}
@string{ECCV = {European Conference on Computer Vision (<b>ECCV</b>)}}
@string{ICCV = {International Conference on Computer Vision (<b>ICCV</b>)}}
@string{NEURIPS = {Conference on Neural Information Processing Systems (<b>NeurIPS</b>)}}
@string{IJCV = {International Journal of Computer Vision (<b>IJCV</b>)}}
@string{ICRA = {IEEE International Conference on Robotics and Automation (<b>ICRA</b>)}}
@string{ICML = {International Conference on Machine Learning (<b>ICML</b>)}}
@string{TMLR = {Transactions on Machine Learning Research (<b>TMLR</b>)}}
@string{arXiv = {arXiv preprint}}

@article{lee2025garasam,
    title={{GaRA-SAM}: Robustifying Segment Anything Model with Gated-Rank Adaptation}, 
    author={Sohyun Lee and Yeho Gwon and Lukas Hoyer and Suha Kwak},
    year={2025},
    eprint={2506.02882},
    journal={arXiv preprint},
    abbr={arXiv},
    primaryClass={cs.CV},
    url={https://arxiv.org/abs/2506.02882}, 
    selected={true},
    img_path={assets/img/publication_preview/lee2025garasam.png},
    abstract={Improving robustness of the Segment Anything Model (SAM) to input degradations is critical for its deployment in high-stakes applications such as autonomous driving and robotics. Our approach to this challenge prioritizes three key aspects: first, parameter efficiency to maintain the inherent generalization capability of SAM; second, fine-grained and input-aware robustification to precisely address the input corruption; and third, adherence to standard training protocols for ease of training. To this end, we propose gated-rank adaptation (GaRA). GaRA introduces lightweight adapters into intermediate layers of the frozen SAM, where each adapter dynamically adjusts the effective rank of its weight matrix based on the input by selectively activating (rank-1) components of the matrix using a learned gating module. This adjustment enables fine-grained and input-aware robustification without compromising the generalization capability of SAM. Our model, GaRA-SAM, significantly outperforms prior work on all robust segmentation benchmarks. In particular, it surpasses the previous best IoU score by up to 21.3%p on ACDC, a challenging real corrupted image dataset.},
    html={https://arxiv.org/abs/2506.02882}
}


@article{gwon2025enhancing,
    title={Enhancing Cost Efficiency in Active Learning with Candidate Set Query}, 
    author={Yeho Gwon and Sehyun Hwang and Hoyoung Kim and Jungseul Ok and Suha Kwak},
    year={2025},
    eprint={2502.06209},
    journal=TMLR,
    abbr={TMLR},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2502.06209}, 
    equal_contrib={true},
    selected={true},
    img_path={assets/img/publication_preview/gwon2025enhancing.png},
    code={https://github.com/yehogwon/csq-al},
    project={csq-al},
    abstract={This paper introduces a cost-efficient active learning (AL) framework for classification, featuring a novel query design called candidate set query. Unlike traditional AL queries requiring the oracle to examine all possible classes, our method narrows down the set of candidate classes likely to include the ground-truth class, significantly reducing the search space and labeling cost. Moreover, we leverage conformal prediction to dynamically generate small yet reliable candidate sets, adapting to model enhancement over successive AL rounds. To this end, we introduce an acquisition function designed to prioritize data points that offer high information gain at lower cost. Empirical evaluations on CIFAR-10, CIFAR-100, and ImageNet64x64 demonstrate the effectiveness and scalability of our framework. Notably, it reduces labeling cost by 42% on ImageNet64x64.},
    html={https://arxiv.org/abs/2502.06209}
}
